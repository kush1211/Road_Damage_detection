{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9066432,"sourceType":"datasetVersion","datasetId":5468123}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nimport tensorflow as tf\nimport xml.etree.ElementTree as ET\nimport glob\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-31T06:25:25.327014Z","iopub.execute_input":"2024-07-31T06:25:25.327767Z","iopub.status.idle":"2024-07-31T06:25:25.332597Z","shell.execute_reply.started":"2024-07-31T06:25:25.327736Z","shell.execute_reply":"2024-07-31T06:25:25.331629Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def find_first_n_files_in_folder(folder_path, n=5):\n    files = []\n    for root, dirs, file_names in os.walk(folder_path):\n        for file_name in file_names:\n            files.append(os.path.join(root, file_name))\n            if len(files) >= n:\n                return files\n    return files\n\n# Example usage\nfolder_path = '/kaggle/input/rdd2022-india/India/test/images'\nfirst_five_files = find_first_n_files_in_folder(folder_path)\nfor file in first_five_files:\n    print(file)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:22:53.263160Z","iopub.execute_input":"2024-07-31T06:22:53.263686Z","iopub.status.idle":"2024-07-31T06:22:54.771679Z","shell.execute_reply.started":"2024-07-31T06:22:53.263660Z","shell.execute_reply":"2024-07-31T06:22:54.770752Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/rdd2022-india/India/test/images/India_000610.jpg\n/kaggle/input/rdd2022-india/India/test/images/India_002833.jpg\n/kaggle/input/rdd2022-india/India/test/images/India_002185.jpg\n/kaggle/input/rdd2022-india/India/test/images/India_005060.jpg\n/kaggle/input/rdd2022-india/India/test/images/India_004591.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"def parse_xml_annotation(xml_file):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    \n    data = {\n        'filename': root.find('filename').text,\n        'width': int(root.find('size/width').text),\n        'height': int(root.find('size/height').text),\n    }\n\n    objects = []\n    for obj in root.findall('object'):\n        if obj.find('name').text in ['D40','D20','D00','D44']:\n#     for obj in root.findall('object'):\n            obj_data = {\n                'class': obj.find('name').text,\n                'xmin': int(obj.find('bndbox/xmin').text),\n                'ymin': int(obj.find('bndbox/ymin').text),\n                'xmax': int(obj.find('bndbox/xmax').text),\n                'ymax': int(obj.find('bndbox/ymax').text),\n            }\n            objects.append(obj_data)\n    \n    data['objects'] = objects\n    return data\n\ndef parse_annotations(annotation_dir):\n    annotations = []\n    for xml_file in tqdm(os.listdir(annotation_dir)):\n        if xml_file.endswith('.xml'):\n            annotation = parse_xml_annotation(os.path.join(annotation_dir, xml_file))\n            annotations.append(annotation)\n    return annotations\n\n# Example usage\nannotation_dir = '/kaggle/input/rdd2022-india/India/train/annotations/xmls'\nannotations = parse_annotations(annotation_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:22:54.772776Z","iopub.execute_input":"2024-07-31T06:22:54.773054Z","iopub.status.idle":"2024-07-31T06:23:20.140715Z","shell.execute_reply.started":"2024-07-31T06:22:54.773030Z","shell.execute_reply":"2024-07-31T06:23:20.139743Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7706 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a59bd25ea214e2991209353dec65d8b"}},"metadata":{}}]},{"cell_type":"code","source":"annotations[0:5]","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.143136Z","iopub.execute_input":"2024-07-31T06:23:20.143468Z","iopub.status.idle":"2024-07-31T06:23:20.152175Z","shell.execute_reply.started":"2024-07-31T06:23:20.143435Z","shell.execute_reply":"2024-07-31T06:23:20.151136Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[{'filename': 'India_007360.jpg', 'width': 720, 'height': 720, 'objects': []},\n {'filename': 'India_006920.jpg',\n  'width': 720,\n  'height': 720,\n  'objects': [{'class': 'D40',\n    'xmin': 551,\n    'ymin': 619,\n    'xmax': 584,\n    'ymax': 647},\n   {'class': 'D40', 'xmin': 380, 'ymin': 573, 'xmax': 413, 'ymax': 601},\n   {'class': 'D40', 'xmin': 216, 'ymin': 628, 'xmax': 328, 'ymax': 687}]},\n {'filename': 'India_000805.jpg', 'width': 720, 'height': 720, 'objects': []},\n {'filename': 'India_000865.jpg',\n  'width': 720,\n  'height': 720,\n  'objects': [{'class': 'D44',\n    'xmin': 272,\n    'ymin': 528,\n    'xmax': 345,\n    'ymax': 580}]},\n {'filename': 'India_004167.jpg', 'width': 720, 'height': 720, 'objects': []}]"},"metadata":{}}]},{"cell_type":"code","source":"len(annotations)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.153601Z","iopub.execute_input":"2024-07-31T06:23:20.153895Z","iopub.status.idle":"2024-07-31T06:23:20.161700Z","shell.execute_reply.started":"2024-07-31T06:23:20.153871Z","shell.execute_reply":"2024-07-31T06:23:20.160799Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"7706"},"metadata":{}}]},{"cell_type":"code","source":"def annotations_to_dataframe(annotations):\n    rows = []\n    for annotation in annotations:\n        filename = annotation['filename']\n        width = annotation['width']\n        height = annotation['height']\n        if not annotation['objects']:\n            row = {\n                'filename': filename,\n                'width': width,\n                'height': height,\n                'class': None,  # No object class\n                'xmin': None,   # No bounding box\n                'ymin': None,\n                'xmax': None,\n                'ymax': None\n            }\n            rows.append(row)\n        else:\n            for obj in annotation['objects']:\n                row = {\n                    'filename': filename,\n                    'width': width,\n                    'height': height,\n                    'class': obj['class'],\n                    'xmin': obj['xmin'],\n                    'ymin': obj['ymin'],\n                    'xmax': obj['xmax'],\n                    'ymax': obj['ymax']\n                }\n                rows.append(row)\n    return pd.DataFrame(rows)\n\n# Example usage\ndf = annotations_to_dataframe(annotations)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.162774Z","iopub.execute_input":"2024-07-31T06:23:20.163062Z","iopub.status.idle":"2024-07-31T06:23:20.251963Z","shell.execute_reply.started":"2024-07-31T06:23:20.163038Z","shell.execute_reply":"2024-07-31T06:23:20.251037Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"               filename  width  height class   xmin   ymin   xmax   ymax\n0      India_007360.jpg    720     720  None    NaN    NaN    NaN    NaN\n1      India_006920.jpg    720     720   D40  551.0  619.0  584.0  647.0\n2      India_006920.jpg    720     720   D40  380.0  573.0  413.0  601.0\n3      India_006920.jpg    720     720   D40  216.0  628.0  328.0  687.0\n4      India_000805.jpg    720     720  None    NaN    NaN    NaN    NaN\n...                 ...    ...     ...   ...    ...    ...    ...    ...\n11880  India_009238.jpg    720     720  None    NaN    NaN    NaN    NaN\n11881  India_007572.jpg    720     720   D40    1.0  421.0  312.0  716.0\n11882  India_007572.jpg    720     720   D40  348.0  442.0  447.0  531.0\n11883  India_000372.jpg    720     720  None    NaN    NaN    NaN    NaN\n11884  India_001539.jpg    720     720  None    NaN    NaN    NaN    NaN\n\n[11885 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>India_007360.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>India_006920.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>551.0</td>\n      <td>619.0</td>\n      <td>584.0</td>\n      <td>647.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>India_006920.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>380.0</td>\n      <td>573.0</td>\n      <td>413.0</td>\n      <td>601.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>India_006920.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>216.0</td>\n      <td>628.0</td>\n      <td>328.0</td>\n      <td>687.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>India_000805.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11880</th>\n      <td>India_009238.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11881</th>\n      <td>India_007572.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>1.0</td>\n      <td>421.0</td>\n      <td>312.0</td>\n      <td>716.0</td>\n    </tr>\n    <tr>\n      <th>11882</th>\n      <td>India_007572.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>348.0</td>\n      <td>442.0</td>\n      <td>447.0</td>\n      <td>531.0</td>\n    </tr>\n    <tr>\n      <th>11883</th>\n      <td>India_000372.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11884</th>\n      <td>India_001539.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>11885 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.252957Z","iopub.execute_input":"2024-07-31T06:23:20.253251Z","iopub.status.idle":"2024-07-31T06:23:20.274940Z","shell.execute_reply.started":"2024-07-31T06:23:20.253226Z","shell.execute_reply":"2024-07-31T06:23:20.274152Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 11885 entries, 0 to 11884\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   filename  11885 non-null  object \n 1   width     11885 non-null  int64  \n 2   height    11885 non-null  int64  \n 3   class     7825 non-null   object \n 4   xmin      7825 non-null   float64\n 5   ymin      7825 non-null   float64\n 6   xmax      7825 non-null   float64\n 7   ymax      7825 non-null   float64\ndtypes: float64(4), int64(2), object(2)\nmemory usage: 742.9+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.to_csv('annotations.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.275989Z","iopub.execute_input":"2024-07-31T06:23:20.276252Z","iopub.status.idle":"2024-07-31T06:23:20.359523Z","shell.execute_reply.started":"2024-07-31T06:23:20.276229Z","shell.execute_reply":"2024-07-31T06:23:20.358682Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.360609Z","iopub.execute_input":"2024-07-31T06:23:20.360938Z","iopub.status.idle":"2024-07-31T06:23:20.371505Z","shell.execute_reply.started":"2024-07-31T06:23:20.360908Z","shell.execute_reply":"2024-07-31T06:23:20.370634Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"filename       0\nwidth          0\nheight         0\nclass       4060\nxmin        4060\nymin        4060\nxmax        4060\nymax        4060\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"final_df =df.copy()\nfinal_df.dropna(inplace=True)\nfinal_df.reset_index(inplace=True)\nfinal_df.drop('index',axis=1,inplace=True)\nfinal_df","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.375092Z","iopub.execute_input":"2024-07-31T06:23:20.375685Z","iopub.status.idle":"2024-07-31T06:23:20.401621Z","shell.execute_reply.started":"2024-07-31T06:23:20.375649Z","shell.execute_reply":"2024-07-31T06:23:20.400640Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"              filename  width  height class   xmin   ymin   xmax   ymax\n0     India_006920.jpg    720     720   D40  551.0  619.0  584.0  647.0\n1     India_006920.jpg    720     720   D40  380.0  573.0  413.0  601.0\n2     India_006920.jpg    720     720   D40  216.0  628.0  328.0  687.0\n3     India_000865.jpg    720     720   D44  272.0  528.0  345.0  580.0\n4     India_009855.jpg    720     720   D44  466.0  663.0  562.0  718.0\n...                ...    ...     ...   ...    ...    ...    ...    ...\n7820  India_002152.jpg    720     720   D44  276.0  501.0  325.0  555.0\n7821  India_009075.jpg    720     720   D20  118.0  486.0  378.0  669.0\n7822  India_009075.jpg    720     720   D20  530.0  487.0  695.0  659.0\n7823  India_007572.jpg    720     720   D40    1.0  421.0  312.0  716.0\n7824  India_007572.jpg    720     720   D40  348.0  442.0  447.0  531.0\n\n[7825 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>India_006920.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>551.0</td>\n      <td>619.0</td>\n      <td>584.0</td>\n      <td>647.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>India_006920.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>380.0</td>\n      <td>573.0</td>\n      <td>413.0</td>\n      <td>601.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>India_006920.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>216.0</td>\n      <td>628.0</td>\n      <td>328.0</td>\n      <td>687.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>India_000865.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D44</td>\n      <td>272.0</td>\n      <td>528.0</td>\n      <td>345.0</td>\n      <td>580.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>India_009855.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D44</td>\n      <td>466.0</td>\n      <td>663.0</td>\n      <td>562.0</td>\n      <td>718.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7820</th>\n      <td>India_002152.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D44</td>\n      <td>276.0</td>\n      <td>501.0</td>\n      <td>325.0</td>\n      <td>555.0</td>\n    </tr>\n    <tr>\n      <th>7821</th>\n      <td>India_009075.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D20</td>\n      <td>118.0</td>\n      <td>486.0</td>\n      <td>378.0</td>\n      <td>669.0</td>\n    </tr>\n    <tr>\n      <th>7822</th>\n      <td>India_009075.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D20</td>\n      <td>530.0</td>\n      <td>487.0</td>\n      <td>695.0</td>\n      <td>659.0</td>\n    </tr>\n    <tr>\n      <th>7823</th>\n      <td>India_007572.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>1.0</td>\n      <td>421.0</td>\n      <td>312.0</td>\n      <td>716.0</td>\n    </tr>\n    <tr>\n      <th>7824</th>\n      <td>India_007572.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>348.0</td>\n      <td>442.0</td>\n      <td>447.0</td>\n      <td>531.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7825 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"base_path = '/kaggle/input/rdd2022-india/India/train/images/'\nfinal_df['image_path'] = final_df['filename'].apply(lambda x: os.path.join(base_path, x))\nfinal_df","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.402573Z","iopub.execute_input":"2024-07-31T06:23:20.402838Z","iopub.status.idle":"2024-07-31T06:23:20.439517Z","shell.execute_reply.started":"2024-07-31T06:23:20.402816Z","shell.execute_reply":"2024-07-31T06:23:20.438651Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"              filename  width  height class   xmin   ymin   xmax   ymax  \\\n0     India_006920.jpg    720     720   D40  551.0  619.0  584.0  647.0   \n1     India_006920.jpg    720     720   D40  380.0  573.0  413.0  601.0   \n2     India_006920.jpg    720     720   D40  216.0  628.0  328.0  687.0   \n3     India_000865.jpg    720     720   D44  272.0  528.0  345.0  580.0   \n4     India_009855.jpg    720     720   D44  466.0  663.0  562.0  718.0   \n...                ...    ...     ...   ...    ...    ...    ...    ...   \n7820  India_002152.jpg    720     720   D44  276.0  501.0  325.0  555.0   \n7821  India_009075.jpg    720     720   D20  118.0  486.0  378.0  669.0   \n7822  India_009075.jpg    720     720   D20  530.0  487.0  695.0  659.0   \n7823  India_007572.jpg    720     720   D40    1.0  421.0  312.0  716.0   \n7824  India_007572.jpg    720     720   D40  348.0  442.0  447.0  531.0   \n\n                                             image_path  \n0     /kaggle/input/rdd2022-india/India/train/images...  \n1     /kaggle/input/rdd2022-india/India/train/images...  \n2     /kaggle/input/rdd2022-india/India/train/images...  \n3     /kaggle/input/rdd2022-india/India/train/images...  \n4     /kaggle/input/rdd2022-india/India/train/images...  \n...                                                 ...  \n7820  /kaggle/input/rdd2022-india/India/train/images...  \n7821  /kaggle/input/rdd2022-india/India/train/images...  \n7822  /kaggle/input/rdd2022-india/India/train/images...  \n7823  /kaggle/input/rdd2022-india/India/train/images...  \n7824  /kaggle/input/rdd2022-india/India/train/images...  \n\n[7825 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>India_006920.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>551.0</td>\n      <td>619.0</td>\n      <td>584.0</td>\n      <td>647.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>India_006920.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>380.0</td>\n      <td>573.0</td>\n      <td>413.0</td>\n      <td>601.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>India_006920.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>216.0</td>\n      <td>628.0</td>\n      <td>328.0</td>\n      <td>687.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>India_000865.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D44</td>\n      <td>272.0</td>\n      <td>528.0</td>\n      <td>345.0</td>\n      <td>580.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>India_009855.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D44</td>\n      <td>466.0</td>\n      <td>663.0</td>\n      <td>562.0</td>\n      <td>718.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7820</th>\n      <td>India_002152.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D44</td>\n      <td>276.0</td>\n      <td>501.0</td>\n      <td>325.0</td>\n      <td>555.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n    <tr>\n      <th>7821</th>\n      <td>India_009075.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D20</td>\n      <td>118.0</td>\n      <td>486.0</td>\n      <td>378.0</td>\n      <td>669.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n    <tr>\n      <th>7822</th>\n      <td>India_009075.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D20</td>\n      <td>530.0</td>\n      <td>487.0</td>\n      <td>695.0</td>\n      <td>659.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n    <tr>\n      <th>7823</th>\n      <td>India_007572.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>1.0</td>\n      <td>421.0</td>\n      <td>312.0</td>\n      <td>716.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n    <tr>\n      <th>7824</th>\n      <td>India_007572.jpg</td>\n      <td>720</td>\n      <td>720</td>\n      <td>D40</td>\n      <td>348.0</td>\n      <td>442.0</td>\n      <td>447.0</td>\n      <td>531.0</td>\n      <td>/kaggle/input/rdd2022-india/India/train/images...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7825 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"final_df['image_path'][0]","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.440618Z","iopub.execute_input":"2024-07-31T06:23:20.440863Z","iopub.status.idle":"2024-07-31T06:23:20.446734Z","shell.execute_reply.started":"2024-07-31T06:23:20.440841Z","shell.execute_reply":"2024-07-31T06:23:20.445735Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/rdd2022-india/India/train/images/India_006920.jpg'"},"metadata":{}}]},{"cell_type":"code","source":"final_df['class'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.447784Z","iopub.execute_input":"2024-07-31T06:23:20.448028Z","iopub.status.idle":"2024-07-31T06:23:20.458684Z","shell.execute_reply.started":"2024-07-31T06:23:20.448004Z","shell.execute_reply":"2024-07-31T06:23:20.457309Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array(['D40', 'D44', 'D20', 'D00'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"class_mapping = {\n    'D40': 0,\n    'D44': 1,\n    'D00': 2,\n    'D20': 3\n}\n\noutput_dir = '/kaggle/working/all_labels'\nos.makedirs(output_dir, exist_ok=True)\n\ndef convert_to_yolo_format(row):\n    if pd.isna(row['class']):\n        return\n\n    class_id = class_mapping[row['class']]\n    x_center = (row['xmin'] + row['xmax']) / 2.0 / row['width']\n    y_center = (row['ymin'] + row['ymax']) / 2.0 / row['height']\n    bbox_width = (row['xmax'] - row['xmin']) / row['width']\n    bbox_height = (row['ymax'] - row['ymin']) / row['height']\n\n    return f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\"\n\ndef write_yolo_annotation(final_df, output_dir):\n    grouped = final_df.groupby('filename')\n    for filename, group in grouped:\n        yolo_annotations = group.apply(convert_to_yolo_format, axis=1).dropna().tolist()\n        label_filename = os.path.join(output_dir, filename.replace('.jpg','.txt'))\n        with open(label_filename, 'w') as f:\n            f.write(\"\\n\".join(yolo_annotations))\n\nwrite_yolo_annotation(final_df, output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:23:20.460037Z","iopub.execute_input":"2024-07-31T06:23:20.460928Z","iopub.status.idle":"2024-07-31T06:23:23.507720Z","shell.execute_reply.started":"2024-07-31T06:23:20.460889Z","shell.execute_reply":"2024-07-31T06:23:23.506677Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"os.makedirs('/kaggle/working/datasets/labels/train/', exist_ok=True)\nos.makedirs('/kaggle/working/datasets/labels/val/', exist_ok=True)\nos.makedirs('/kaggle/working/datasets/images/train/', exist_ok=True)\nos.makedirs('/kaggle/working/datasets/images/val/', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:30:03.901070Z","iopub.execute_input":"2024-07-31T06:30:03.901810Z","iopub.status.idle":"2024-07-31T06:30:03.907326Z","shell.execute_reply.started":"2024-07-31T06:30:03.901775Z","shell.execute_reply":"2024-07-31T06:30:03.906396Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"label_source_dir = '/kaggle/working/all_labels'\nlabel_train_dir = '/kaggle/working/datasets/labels/train/'\nlabel_val_dir = '/kaggle/working/datasets/labels/val/'\n\nimage_source_dir ='/kaggle/input/rdd2022-india/India/train/images'\nimage_train_dir = '/kaggle/working/datasets/images/train/'\nimage_val_dir = '/kaggle/working/datasets/images/val/'\n\nimage_files = final_df['image_path'].unique()\ntrain_files = image_files[:int(0.8*len(image_files))]\nval_files = image_files[int(0.8*len(image_files)):]\n\ntrain_images = [os.path.splitext(os.path.basename(path.strip()))[0] + \".jpg\" for path in train_files]\nval_images = [os.path.splitext(os.path.basename(path.strip()))[0] + \".jpg\" for path in val_files]\ntrain_labels = [os.path.splitext(os.path.basename(path.strip()))[0] + \".txt\" for path in train_files]\nval_labels = [os.path.splitext(os.path.basename(path.strip()))[0] + \".txt\" for path in val_files]\n\n\nfor filename in train_images:\n    if filename.endswith('.jpg'):  # Ensure we're only moving label files\n        shutil.copy(os.path.join(image_source_dir, filename), os.path.join(image_train_dir, filename))\nfor filename in val_images:\n    if filename.endswith('.jpg'):  # Ensure we're only moving label files\n        shutil.copy(os.path.join(image_source_dir, filename), os.path.join(image_val_dir, filename))\n\nfor filename in train_labels:\n    if filename.endswith('.txt'):  # Ensure we're only moving label files\n        shutil.move(os.path.join(label_source_dir, filename), os.path.join(label_train_dir, filename))\nfor filename in val_labels:\n    if filename.endswith('.txt'):  # Ensure we're only moving label files\n        shutil.move(os.path.join(label_source_dir, filename), os.path.join(label_val_dir, filename))\n\n        \n\n# with open('/kaggle/working/dataset/images/train', 'w') as f:\n#     for item in train_files:\n#         f.write(\"%s\\n\" % item)\n        \n        \n\n# with open('/kaggle/working/val.txt', 'w') as f:\n#     for item in val_files:\n#         f.write(\"%s\\n\" % item)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:38:46.448314Z","iopub.execute_input":"2024-07-31T06:38:46.449271Z","iopub.status.idle":"2024-07-31T06:38:50.578821Z","shell.execute_reply.started":"2024-07-31T06:38:46.449235Z","shell.execute_reply":"2024-07-31T06:38:50.577632Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:816\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/all_labels/India_006920.txt' -> '/kaggle/working/datasets/labels/train/India_006920.txt'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m train_labels:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Ensure we're only moving label files\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m         \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_source_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_train_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m val_labels:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Ensure we're only moving label files\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:836\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m         rmtree(src)\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:254\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/all_labels/India_006920.txt'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/all_labels/India_006920.txt'","output_type":"error"}]},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5\n%cd yolov5","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:32:46.852594Z","iopub.execute_input":"2024-07-31T06:32:46.853500Z","iopub.status.idle":"2024-07-31T06:32:49.266756Z","shell.execute_reply.started":"2024-07-31T06:32:46.853463Z","shell.execute_reply":"2024-07-31T06:32:49.265666Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 16836, done.\u001b[K\nremote: Counting objects: 100% (11/11), done.\u001b[K\nremote: Compressing objects: 100% (11/11), done.\u001b[K\nremote: Total 16836 (delta 1), reused 6 (delta 0), pack-reused 16825\u001b[K\nReceiving objects: 100% (16836/16836), 15.57 MiB | 32.14 MiB/s, done.\nResolving deltas: 100% (11550/11550), done.\n/kaggle/working/yolov5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create the dataset.yaml file\ndataset_yaml = \"\"\"\ntrain: /kaggle/working/datasets/images/train\nval: /kaggle/working/datasets/images/val\n\n# Number of classes\nnc: 4\n\n# Class names\nnames: [0, 1, 2, 3]\n\"\"\"\n\n# Save the dataset.yaml file\nwith open('/kaggle/working/dataset.yaml', 'w') as f:\n    f.write(dataset_yaml)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:33:13.962218Z","iopub.execute_input":"2024-07-31T06:33:13.963233Z","iopub.status.idle":"2024-07-31T06:33:13.969050Z","shell.execute_reply.started":"2024-07-31T06:33:13.963192Z","shell.execute_reply":"2024-07-31T06:33:13.968025Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:33:16.980321Z","iopub.execute_input":"2024-07-31T06:33:16.981188Z","iopub.status.idle":"2024-07-31T06:33:44.803586Z","shell.execute_reply.started":"2024-07-31T06:33:16.981154Z","shell.execute_reply":"2024-07-31T06:33:44.801950Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gitpython>=3.1.30 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.1.41)\nRequirement already satisfied: matplotlib>=3.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.7.5)\nRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.10.0.84)\nCollecting pillow>=10.3.0 (from -r requirements.txt (line 9))\n  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (5.9.3)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (6.0.1)\nRequirement already satisfied: requests>=2.32.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.11.4)\nCollecting thop>=0.1.1 (from -r requirements.txt (line 14))\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (4.66.4)\nCollecting ultralytics>=8.2.34 (from -r requirements.txt (line 18))\n  Downloading ultralytics-8.2.70-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.12.2)\nCollecting setuptools>=70.0.0 (from -r requirements.txt (line 42))\n  Downloading setuptools-72.1.0-py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.5.0)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r requirements.txt (line 18))\n  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\nDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nDownloading ultralytics-8.2.70-py3-none-any.whl (862 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.6/862.6 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading setuptools-72.1.0-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\nInstalling collected packages: setuptools, pillow, ultralytics-thop, thop, ultralytics\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 69.0.3\n    Uninstalling setuptools-69.0.3:\n      Successfully uninstalled setuptools-69.0.3\n  Attempting uninstall: pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nconda 24.5.0 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pillow-10.4.0 setuptools-72.1.0 thop-0.1.1.post2209072238 ultralytics-8.2.70 ultralytics-thop-2.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!wandb off","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:33:52.634871Z","iopub.execute_input":"2024-07-31T06:33:52.635230Z","iopub.status.idle":"2024-07-31T06:33:54.882357Z","shell.execute_reply.started":"2024-07-31T06:33:52.635202Z","shell.execute_reply":"2024-07-31T06:33:54.881341Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"W&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.\n","output_type":"stream"}]},{"cell_type":"code","source":"!python train.py --img 640 --batch 16 --epochs 50 --data /kaggle/working/dataset.yaml --cfg yolov5s.yaml --weights yolov5s.pt --name road_damage_detection","metadata":{"execution":{"iopub.status.busy":"2024-07-31T06:40:23.387104Z","iopub.execute_input":"2024-07-31T06:40:23.387835Z","iopub.status.idle":"2024-07-31T07:47:32.363333Z","shell.execute_reply.started":"2024-07-31T06:40:23.387798Z","shell.execute_reply":"2024-07-31T07:47:32.361930Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n2024-07-31 06:40:31.018727: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-31 06:40:31.018784: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-31 06:40:31.020330: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=/kaggle/working/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=road_damage_detection, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\nYOLOv5 🚀 v7.0-350-g6096750f Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=4\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\nYOLOv5s summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n\nTransferred 342/349 items from yolov5s.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\nWARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\nSee Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/labels/train.cache... 2916 images, 0 ba\u001b[0m\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/labels/val... 730 images, 0 backgrounds, \u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/labels/val.cache\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.84 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\nPlotting labels to runs/train/road_damage_detection2/labels.jpg... \n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/road_damage_detection2\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       0/49      1.86G    0.08955    0.03399    0.04056          9        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574    0.00717      0.329     0.0161    0.00428\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/49      2.67G    0.07303    0.03106    0.03003         14        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.186      0.273      0.147     0.0446\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/49      2.67G    0.06813    0.02851    0.02369         18        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.274      0.314      0.202     0.0633\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/49      2.67G    0.06465    0.02836    0.02191         17        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.277       0.34       0.23     0.0751\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/49      2.67G    0.06224    0.02815    0.02112         11        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.285       0.29      0.197       0.07\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/49      2.67G    0.06094    0.02783    0.01947          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.339      0.367        0.3      0.115\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/49      2.67G    0.05918    0.02806     0.0184         18        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.404      0.334      0.288      0.105\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/49      2.67G    0.05876    0.02738    0.01773         16        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.411       0.39      0.346      0.127\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/49      2.67G    0.05749    0.02704    0.01664         16        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.403      0.359      0.313      0.117\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/49      2.67G    0.05683    0.02791    0.01632         14        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.453      0.384      0.377      0.149\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/49      2.67G    0.05608    0.02693    0.01586         11        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.416      0.358      0.335      0.139\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/49      2.67G    0.05514    0.02661    0.01474          6        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.446      0.427      0.402      0.163\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/49      2.67G    0.05459    0.02619    0.01403         11        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.422      0.441      0.396      0.155\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/49      2.67G    0.05452    0.02656    0.01412         24        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.446      0.357      0.331      0.134\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/49      2.67G    0.05369    0.02544     0.0138          8        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.503      0.405      0.409      0.165\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/49      2.67G    0.05379    0.02692     0.0138         13        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.476      0.455      0.429      0.177\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/49      2.67G    0.05304    0.02637    0.01279          8        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.495       0.42      0.418      0.171\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/49      2.67G    0.05231    0.02638    0.01256          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.497      0.453      0.443      0.178\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/49      2.67G    0.05233    0.02562    0.01202         10        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.494      0.447       0.43      0.172\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/49      2.67G    0.05176    0.02563    0.01204          7        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.497      0.466      0.456      0.186\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/49      2.67G    0.05125    0.02542    0.01202         13        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.513      0.419      0.411      0.169\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/49      2.67G    0.05138    0.02602    0.01137         17        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.511      0.465      0.458      0.185\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/49      2.67G    0.05042    0.02549    0.01096          9        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.527      0.444      0.445      0.187\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/49      2.67G    0.05032    0.02536     0.0108         11        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.551       0.47      0.482      0.199\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/49      2.67G    0.04996    0.02472    0.01045         12        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574        0.5      0.489      0.461      0.191\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      25/49      2.67G    0.04941    0.02493   0.009918          8        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.524      0.468      0.456      0.189\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      26/49      2.67G    0.04917    0.02481   0.009557         20        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.509      0.487      0.477      0.198\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      27/49      2.67G    0.04905    0.02539   0.009578         10        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.532      0.463      0.464      0.192\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      28/49      2.67G    0.04872    0.02413   0.009772         13        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.501      0.495      0.483      0.203\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      29/49      2.67G    0.04815    0.02395   0.009662         12        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.547      0.448      0.476      0.189\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      30/49      2.67G    0.04853    0.02485   0.009711         15        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.528      0.479      0.477      0.197\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      31/49      2.67G    0.04769    0.02459   0.008917         21        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.532      0.519      0.501      0.207\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      32/49      2.67G     0.0471    0.02405   0.008501         11        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.535      0.499      0.498      0.212\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      33/49      2.67G    0.04671    0.02386   0.008545          8        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.532      0.479       0.46       0.19\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      34/49      2.67G    0.04627    0.02402   0.007982         10        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.493      0.517      0.486      0.204\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      35/49      2.67G    0.04603    0.02379   0.007612         11        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.548      0.517      0.507      0.209\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      36/49      2.67G    0.04552     0.0234   0.007134         21        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.564      0.467      0.477      0.202\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      37/49      2.67G    0.04557    0.02424   0.007715         18        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.592      0.505      0.518      0.221\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      38/49      2.67G    0.04484    0.02349   0.007252          9        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.498      0.522      0.483      0.201\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      39/49      2.67G     0.0447     0.0241   0.007213         11        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.559      0.521      0.506      0.208\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      40/49      2.67G      0.044    0.02332   0.006919          9        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.566      0.507      0.498      0.205\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      41/49      2.67G    0.04365    0.02294    0.00654         10        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.566      0.512      0.505      0.215\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      42/49      2.67G    0.04358    0.02289   0.006771         13        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.564      0.502      0.508      0.214\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      43/49      2.67G    0.04339    0.02359   0.006398         15        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.566      0.511      0.511      0.212\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      44/49      2.67G    0.04284    0.02253    0.00602          9        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.552      0.522      0.499      0.207\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      45/49      2.67G    0.04248    0.02226   0.006046         13        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.598      0.496      0.517      0.219\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      46/49      2.67G    0.04212    0.02196   0.005917         12        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.582      0.517      0.524      0.223\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      47/49      2.67G    0.04181    0.02256    0.00571         18        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.563      0.527      0.517      0.218\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      48/49      2.67G    0.04176    0.02213   0.005878         21        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.605      0.502      0.516      0.218\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      49/49      2.67G    0.04129    0.02194   0.005533          8        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.604      0.515      0.523      0.221\n\n50 epochs completed in 1.108 hours.\nOptimizer stripped from runs/train/road_damage_detection2/weights/last.pt, 14.5MB\nOptimizer stripped from runs/train/road_damage_detection2/weights/best.pt, 14.5MB\n\nValidating runs/train/road_damage_detection2/weights/best.pt...\nFusing layers... \nYOLOv5s summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all        730       1574      0.585      0.518      0.525      0.223\n                     0        730        660       0.59      0.433      0.469      0.157\n                     1        730        223      0.602      0.677      0.636      0.318\n                     2        730        297      0.468      0.414      0.363      0.149\n                     3        730        394      0.679      0.546      0.629      0.268\nResults saved to \u001b[1mruns/train/road_damage_detection2\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# cache_path = '/kaggle/working/'\n# if os.path.exists(cache_path):\n#     os.remove(cache_path)\n#     print(f\"The cache file '{cache_path}' has been deleted.\")\n# else:\n#     print(f\"The cache file '{cache_path}' does not exist.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-31T05:45:29.229764Z","iopub.execute_input":"2024-07-31T05:45:29.230321Z","iopub.status.idle":"2024-07-31T05:45:29.266817Z","shell.execute_reply.started":"2024-07-31T05:45:29.230292Z","shell.execute_reply":"2024-07-31T05:45:29.265659Z"},"trusted":true},"execution_count":41,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m cache_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_path):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe cache file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been deleted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/kaggle/working/'"],"ename":"IsADirectoryError","evalue":"[Errno 21] Is a directory: '/kaggle/working/'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}